{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "# !pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install joblib. This will be used to save your model. \n",
    "# Restart your kernel after installing \n",
    "# !pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>day</th>\n",
       "      <th>station</th>\n",
       "      <th>code</th>\n",
       "      <th>min_delay</th>\n",
       "      <th>min_gap</th>\n",
       "      <th>bound</th>\n",
       "      <th>line</th>\n",
       "      <th>vehicle</th>\n",
       "      <th>code_info</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>line_name</th>\n",
       "      <th>month</th>\n",
       "      <th>time_range</th>\n",
       "      <th>month_number</th>\n",
       "      <th>hour</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7720.0</td>\n",
       "      <td>2018-02-13</td>\n",
       "      <td>6:57</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>BROADVIEW STATION</td>\n",
       "      <td>EUNT</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>W</td>\n",
       "      <td>BD</td>\n",
       "      <td>5285.0</td>\n",
       "      <td>Equipment - No Trouble Found</td>\n",
       "      <td>43.4037</td>\n",
       "      <td>-79.2130</td>\n",
       "      <td>Bloor Danforth</td>\n",
       "      <td>February</td>\n",
       "      <td>5-9AM</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3147.0</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>11:54</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>COXWELL STATION</td>\n",
       "      <td>TUNIP</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>W</td>\n",
       "      <td>BD</td>\n",
       "      <td>5350.0</td>\n",
       "      <td>Operator Not In Position</td>\n",
       "      <td>43.4103</td>\n",
       "      <td>-79.1923</td>\n",
       "      <td>Bloor Danforth</td>\n",
       "      <td>June</td>\n",
       "      <td>9AM-12PM</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11036.0</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>17:05</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>COXWELL STATION</td>\n",
       "      <td>TUNOA</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>E</td>\n",
       "      <td>BD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No Operator Immediately Available</td>\n",
       "      <td>43.4103</td>\n",
       "      <td>-79.1923</td>\n",
       "      <td>Bloor Danforth</td>\n",
       "      <td>July</td>\n",
       "      <td>3-6PM</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11037.0</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>17:33</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>COXWELL STATION</td>\n",
       "      <td>TUNOA</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>E</td>\n",
       "      <td>BD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No Operator Immediately Available</td>\n",
       "      <td>43.4103</td>\n",
       "      <td>-79.1923</td>\n",
       "      <td>Bloor Danforth</td>\n",
       "      <td>July</td>\n",
       "      <td>3-6PM</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11038.0</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>17:40</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>COXWELL STATION</td>\n",
       "      <td>TUNOA</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>W</td>\n",
       "      <td>BD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No Operator Immediately Available</td>\n",
       "      <td>43.4103</td>\n",
       "      <td>-79.1923</td>\n",
       "      <td>Bloor Danforth</td>\n",
       "      <td>July</td>\n",
       "      <td>3-6PM</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id        date   time        day            station   code  min_delay  \\\n",
       "0   7720.0  2018-02-13   6:57    Tuesday  BROADVIEW STATION   EUNT        2.0   \n",
       "1   3147.0  2019-06-12  11:54  Wednesday    COXWELL STATION  TUNIP        2.0   \n",
       "2  11036.0  2018-07-31  17:05    Tuesday    COXWELL STATION  TUNOA        2.0   \n",
       "3  11037.0  2018-07-31  17:33    Tuesday    COXWELL STATION  TUNOA        2.0   \n",
       "4  11038.0  2018-07-31  17:40    Tuesday    COXWELL STATION  TUNOA        2.0   \n",
       "\n",
       "   min_gap bound line  vehicle                           code_info  latitude  \\\n",
       "0      4.0     W   BD   5285.0        Equipment - No Trouble Found   43.4037   \n",
       "1      5.0     W   BD   5350.0            Operator Not In Position   43.4103   \n",
       "2      4.0     E   BD      0.0  No Operator Immediately Available    43.4103   \n",
       "3      4.0     E   BD      0.0  No Operator Immediately Available    43.4103   \n",
       "4      4.0     W   BD      0.0  No Operator Immediately Available    43.4103   \n",
       "\n",
       "   longitude       line_name     month time_range  month_number  hour    year  \n",
       "0   -79.2130  Bloor Danforth  February      5-9AM           2.0   6.0  2018.0  \n",
       "1   -79.1923  Bloor Danforth      June   9AM-12PM           6.0  11.0  2019.0  \n",
       "2   -79.1923  Bloor Danforth      July      3-6PM           7.0  17.0  2018.0  \n",
       "3   -79.1923  Bloor Danforth      July      3-6PM           7.0  17.0  2018.0  \n",
       "4   -79.1923  Bloor Danforth      July      3-6PM           7.0  17.0  2018.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the dataset used contains all delays under 30 mins. \n",
    "df = pd.read_csv(\"../Data/ttc_subway_delay_2018_2019_for_machine_learning.csv\", encoding='unicode_escape')\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "df.head()\n",
    "# one hot encoding for stations - 1 or 0. will create many columns\n",
    "# min_delay\n",
    "# time series model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select your features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>min_delay</th>\n",
       "      <th>min_gap</th>\n",
       "      <th>vehicle</th>\n",
       "      <th>month_number</th>\n",
       "      <th>hour</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BROADVIEW STATION</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5285.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COXWELL STATION</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5350.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COXWELL STATION</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COXWELL STATION</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COXWELL STATION</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             station  min_delay  min_gap  vehicle  month_number  hour    year\n",
       "0  BROADVIEW STATION        2.0      4.0   5285.0           2.0   6.0  2018.0\n",
       "1    COXWELL STATION        2.0      5.0   5350.0           6.0  11.0  2019.0\n",
       "2    COXWELL STATION        2.0      4.0      0.0           7.0  17.0  2018.0\n",
       "3    COXWELL STATION        2.0      4.0      0.0           7.0  17.0  2018.0\n",
       "4    COXWELL STATION        2.0      4.0      0.0           7.0  17.0  2018.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the null rows, and everything that is not a float except station\n",
    "df = df.dropna().drop(['id','date','time','day','code','bound','line','code_info','line_name','month','time_range',\"latitude\",\"longitude\"], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13315, 6) (13315, 1)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(\"station\", axis=1)\n",
    "y = df[\"min_delay\"].values.reshape(-1, 1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_delay</th>\n",
       "      <th>min_gap</th>\n",
       "      <th>vehicle</th>\n",
       "      <th>month_number</th>\n",
       "      <th>hour</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12243</th>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5856.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2421</th>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3026.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11114</th>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5102.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4884</th>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5047.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8624</th>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5596.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       min_delay  min_gap  vehicle  month_number  hour    year\n",
       "12243       10.0     15.0   5856.0          11.0   0.0  2019.0\n",
       "2421         3.0      8.0   3026.0           5.0  10.0  2019.0\n",
       "11114        7.0     13.0   5102.0          11.0   1.0  2019.0\n",
       "4884         4.0      6.0   5047.0          10.0  19.0  2019.0\n",
       "8624         5.0      8.0   5596.0           3.0  15.0  2018.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_scaler = MinMaxScaler().fit(y_train)\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9986, 6) (9986, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled.shape, y_train_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28571429],\n",
       "       [0.03571429],\n",
       "       [0.17857143],\n",
       "       ...,\n",
       "       [0.07142857],\n",
       "       [0.03571429],\n",
       "       [0.10714286]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3329, 6) (3329, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_scaled.shape, y_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(units=12, activation='relu',kernel_initializer='normal')) #how many units should we have?\n",
    "model.add(Dense(units=8, activation='relu'))\n",
    "model.add(Dense(units=8, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9986 samples\n",
      "Epoch 1/40\n",
      "9986/9986 - 2s - loss: 5.4213 - accuracy: 0.0000e+00\n",
      "Epoch 2/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 3/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 4/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 5/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 6/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 7/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 8/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 9/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 10/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 11/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 12/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 13/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 14/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 15/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 16/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 17/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 18/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 19/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 20/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 21/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 22/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 23/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 24/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 25/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 26/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 27/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 28/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 29/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 30/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 31/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 32/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 33/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 34/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 35/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 36/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 37/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 38/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 39/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n",
      "Epoch 40/40\n",
      "9986/9986 - 1s - loss: 10.2099 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b37cac1eb8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_scaled,\n",
    "    epochs=40, #did I over train?\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3329/3329 - 0s - loss: 10.2402 - accuracy: 0.0000e+00\n",
      "Normal Neural Network - Loss: 10.240244282441441, Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_scaled, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             multiple                  35        \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             multiple                  60        \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             multiple                  165       \n",
      "=================================================================\n",
      "Total params: 260\n",
      "Trainable params: 260\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-55d0a3c20ae0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# prediction result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'score'"
     ]
    }
   ],
   "source": [
    "# prediction result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_predictions = model.predict_classes(X_test_scaled[:5])\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_model.sav']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using results above to save the best model\n",
    "best_model=SVC(kernel='linear', C=10, gamma=0.0001)\n",
    "\n",
    "import joblib\n",
    "\n",
    "filename = 'best_model.sav'\n",
    "joblib.dump(best_model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnew = np.array([[40, 0, 26, 9000, 8000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnew= x_scaler.transform(Xnew)\n",
    "ynew= model2.predict(Xnew)\n",
    "#invert normalize\n",
    "ynew = y_scaler.inverse_transform(ynew) \n",
    "Xnew = x_scaler.inverse_transform(Xnew)\n",
    "print(\"X=%s, Predicted=%s\" % (Xnew[0], ynew[0]))"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
